{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize,wordpunct_tokenize,sent_tokenize \n",
    "from nltk.corpus import stopwords \n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC, NuSVC,SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score,precision_score,recall_score, classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the data and define the columns\n",
    "df1 = pd.read_csv('./data-2_train.csv')\n",
    "df1.columns = ['example_id', 'text', 'aspect_term', 'term_location', 'class']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing n gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6410327595780122"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df1.copy()\n",
    "data2 = data.copy()\n",
    "vec = TfidfVectorizer(min_df = 0.00125, max_df = 0.7, sublinear_tf=True, use_idf=True, stop_words=u'english', analyzer= 'word', ngram_range=(1,5),lowercase=True)\n",
    "X = vec.fit_transform(data['text'])\n",
    "svm = LinearSVC(C=1.2)\n",
    "pred_weights = cross_val_predict(svm,X,data['class'],cv = 10)\n",
    "np.mean(pred_weights == data['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3716"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#intitalize count vectorizer\n",
    "countVectorizer = CountVectorizer()\n",
    "#get the list of vocab\n",
    "count_matrix = countVectorizer.fit_transform(df1['text'])\n",
    "vocab = list(countVectorizer.vocabulary_.keys())\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>text</th>\n",
       "      <th>aspect_term</th>\n",
       "      <th>term_location</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3121_0</td>\n",
       "      <td>But the staff was so horrible to us.</td>\n",
       "      <td>staff</td>\n",
       "      <td>8--13</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2777_0</td>\n",
       "      <td>To be completely fair[comma] the only redeemin...</td>\n",
       "      <td>food</td>\n",
       "      <td>57--61</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1634_0</td>\n",
       "      <td>The food is uniformly exceptional[comma] with ...</td>\n",
       "      <td>food</td>\n",
       "      <td>4--8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1634_1</td>\n",
       "      <td>The food is uniformly exceptional[comma] with ...</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>55--62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1634_2</td>\n",
       "      <td>The food is uniformly exceptional[comma] with ...</td>\n",
       "      <td>menu</td>\n",
       "      <td>141--145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  example_id                                               text aspect_term  \\\n",
       "0     3121_0               But the staff was so horrible to us.       staff   \n",
       "1     2777_0  To be completely fair[comma] the only redeemin...        food   \n",
       "2     1634_0  The food is uniformly exceptional[comma] with ...        food   \n",
       "3     1634_1  The food is uniformly exceptional[comma] with ...     kitchen   \n",
       "4     1634_2  The food is uniformly exceptional[comma] with ...        menu   \n",
       "\n",
       "  term_location  class  \n",
       "0         8--13     -1  \n",
       "1        57--61      1  \n",
       "2          4--8      1  \n",
       "3        55--62      1  \n",
       "4      141--145      0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processData(data):\n",
    "    #replace [comma] with a ','\n",
    "    data = data.replace(\"[comma]\",\",\")\n",
    "    \n",
    "    #tokenize with punctuations\n",
    "    data = \" \".join(wordpunct_tokenize(data))\n",
    "    \n",
    "    #remove punctuations\n",
    "    nopunc = [char for char in data if char not in string.punctuation]\n",
    "    \n",
    "    #join the words and remove stopswords\n",
    "    data = \"\".join(nopunc)\n",
    "    data = [text for text in data.strip().split() if text not in set(stopwords.words('english'))]  \n",
    "    #message = [snowball.stem(w) for w in message]\n",
    "    \n",
    "    #convert the text into word tokens\n",
    "    data = \" \".join(data)\n",
    "    words = word_tokenize(data)\n",
    "    \n",
    "    #lemmatize using wordNetLemmatizer\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    data = [lemmatizer.lemmatize(word) for word in words]\n",
    "    \n",
    "    #return processed data\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process text and aspect term columns of input data\n",
    "df1['clean_text'] = df1['text'].apply(processData)\n",
    "df1['clean_aspect_term'] = df1['aspect_term'].apply(processData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>text</th>\n",
       "      <th>aspect_term</th>\n",
       "      <th>term_location</th>\n",
       "      <th>class</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_aspect_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3121_0</td>\n",
       "      <td>But the staff was so horrible to us.</td>\n",
       "      <td>staff</td>\n",
       "      <td>8--13</td>\n",
       "      <td>-1</td>\n",
       "      <td>[But, staff, horrible, u]</td>\n",
       "      <td>[staff]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2777_0</td>\n",
       "      <td>To be completely fair[comma] the only redeemin...</td>\n",
       "      <td>food</td>\n",
       "      <td>57--61</td>\n",
       "      <td>1</td>\n",
       "      <td>[To, completely, fair, redeeming, factor, food...</td>\n",
       "      <td>[food]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1634_0</td>\n",
       "      <td>The food is uniformly exceptional[comma] with ...</td>\n",
       "      <td>food</td>\n",
       "      <td>4--8</td>\n",
       "      <td>1</td>\n",
       "      <td>[The, food, uniformly, exceptional, capable, k...</td>\n",
       "      <td>[food]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1634_1</td>\n",
       "      <td>The food is uniformly exceptional[comma] with ...</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>55--62</td>\n",
       "      <td>1</td>\n",
       "      <td>[The, food, uniformly, exceptional, capable, k...</td>\n",
       "      <td>[kitchen]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1634_2</td>\n",
       "      <td>The food is uniformly exceptional[comma] with ...</td>\n",
       "      <td>menu</td>\n",
       "      <td>141--145</td>\n",
       "      <td>0</td>\n",
       "      <td>[The, food, uniformly, exceptional, capable, k...</td>\n",
       "      <td>[menu]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  example_id                                               text aspect_term  \\\n",
       "0     3121_0               But the staff was so horrible to us.       staff   \n",
       "1     2777_0  To be completely fair[comma] the only redeemin...        food   \n",
       "2     1634_0  The food is uniformly exceptional[comma] with ...        food   \n",
       "3     1634_1  The food is uniformly exceptional[comma] with ...     kitchen   \n",
       "4     1634_2  The food is uniformly exceptional[comma] with ...        menu   \n",
       "\n",
       "  term_location  class                                         clean_text  \\\n",
       "0         8--13     -1                          [But, staff, horrible, u]   \n",
       "1        57--61      1  [To, completely, fair, redeeming, factor, food...   \n",
       "2          4--8      1  [The, food, uniformly, exceptional, capable, k...   \n",
       "3        55--62      1  [The, food, uniformly, exceptional, capable, k...   \n",
       "4      141--145      0  [The, food, uniformly, exceptional, capable, k...   \n",
       "\n",
       "  clean_aspect_term  \n",
       "0           [staff]  \n",
       "1            [food]  \n",
       "2            [food]  \n",
       "3         [kitchen]  \n",
       "4            [menu]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method to assign weights\n",
    "def assign_weights(data):\n",
    "    \n",
    "    #get the te\n",
    "    text = data[0]\n",
    "    aspect =data[1]\n",
    "    \n",
    "    #corner case to check aspect terms are lesser or equal to the text\n",
    "    if set(aspect) <= set(text):\n",
    "        \n",
    "        #to store left and right weights\n",
    "        leftWeights = rightWeights = []\n",
    "        \n",
    "        #find the starting point of the first aspect term word\n",
    "        aspect_start = [i for i, word in enumerate(text) if word == aspect[0]]\n",
    "        \n",
    "        #find the start and end indices of the aspect\n",
    "        for pos in (aspect_start):\n",
    "            if  text[(pos + len(aspect) - 1)] == aspect[-1]:\n",
    "                start_index = pos\n",
    "                end_index = pos + len(aspect) - 1\n",
    "                break\n",
    "                \n",
    "        #assign weights to each word moving left and right of the aspect term         \n",
    "        if (end_index - start_index) == len(aspect) - 1:\n",
    "            #get the left side and the right side of the text from the aspect\n",
    "            left_text = text[:start_index]\n",
    "            right_text = text[end_index+1:]\n",
    "            \n",
    "            #generate left and right weights based on a well known strategy\n",
    "            leftWeights = [1/i for i in range(len(left_text),0,-1) if len(left_text) != 0]\n",
    "            rightWeights = [1/i for i in range(1,len(right_text)+1) if len(right_text) != 0]\n",
    "         \n",
    "        #find the total weights by adding a constant\n",
    "        tot_weights = leftWeights + [2]*len(aspect) + rightWeights\n",
    "        \n",
    "        #return the dict of text and its weights\n",
    "        return dict(zip(text,tot_weights))\n",
    "    else: \n",
    "        return np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>text</th>\n",
       "      <th>aspect_term</th>\n",
       "      <th>term_location</th>\n",
       "      <th>class</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_aspect_term</th>\n",
       "      <th>weights_score</th>\n",
       "      <th>element_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3121_0</td>\n",
       "      <td>But the staff was so horrible to us.</td>\n",
       "      <td>staff</td>\n",
       "      <td>8--13</td>\n",
       "      <td>-1</td>\n",
       "      <td>[But, staff, horrible, u]</td>\n",
       "      <td>[staff]</td>\n",
       "      <td>{'But': 1.0, 'staff': 2, 'horrible': 1.0, 'u':...</td>\n",
       "      <td>{'But': 1.0, 'staff': 2, 'horrible': 1.0, 'u':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2777_0</td>\n",
       "      <td>To be completely fair[comma] the only redeemin...</td>\n",
       "      <td>food</td>\n",
       "      <td>57--61</td>\n",
       "      <td>1</td>\n",
       "      <td>[To, completely, fair, redeeming, factor, food...</td>\n",
       "      <td>[food]</td>\n",
       "      <td>{'To': 0.2, 'completely': 0.25, 'fair': 0.3333...</td>\n",
       "      <td>{'To': 0.2, 'completely': 0.25, 'fair': 0.3333...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1634_0</td>\n",
       "      <td>The food is uniformly exceptional[comma] with ...</td>\n",
       "      <td>food</td>\n",
       "      <td>4--8</td>\n",
       "      <td>1</td>\n",
       "      <td>[The, food, uniformly, exceptional, capable, k...</td>\n",
       "      <td>[food]</td>\n",
       "      <td>{'The': 1.0, 'food': 2, 'uniformly': 1.0, 'exc...</td>\n",
       "      <td>{'The': 1.0, 'food': 2, 'uniformly': 1.0, 'exc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1634_1</td>\n",
       "      <td>The food is uniformly exceptional[comma] with ...</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>55--62</td>\n",
       "      <td>1</td>\n",
       "      <td>[The, food, uniformly, exceptional, capable, k...</td>\n",
       "      <td>[kitchen]</td>\n",
       "      <td>{'The': 0.2, 'food': 0.25, 'uniformly': 0.3333...</td>\n",
       "      <td>{'The': 0.2, 'food': 0.25, 'uniformly': 0.3333...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1634_2</td>\n",
       "      <td>The food is uniformly exceptional[comma] with ...</td>\n",
       "      <td>menu</td>\n",
       "      <td>141--145</td>\n",
       "      <td>0</td>\n",
       "      <td>[The, food, uniformly, exceptional, capable, k...</td>\n",
       "      <td>[menu]</td>\n",
       "      <td>{'The': 0.07692307692307693, 'food': 0.0833333...</td>\n",
       "      <td>{'The': 0.07692307692307693, 'food': 0.0833333...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  example_id                                               text aspect_term  \\\n",
       "0     3121_0               But the staff was so horrible to us.       staff   \n",
       "1     2777_0  To be completely fair[comma] the only redeemin...        food   \n",
       "2     1634_0  The food is uniformly exceptional[comma] with ...        food   \n",
       "3     1634_1  The food is uniformly exceptional[comma] with ...     kitchen   \n",
       "4     1634_2  The food is uniformly exceptional[comma] with ...        menu   \n",
       "\n",
       "  term_location  class                                         clean_text  \\\n",
       "0         8--13     -1                          [But, staff, horrible, u]   \n",
       "1        57--61      1  [To, completely, fair, redeeming, factor, food...   \n",
       "2          4--8      1  [The, food, uniformly, exceptional, capable, k...   \n",
       "3        55--62      1  [The, food, uniformly, exceptional, capable, k...   \n",
       "4      141--145      0  [The, food, uniformly, exceptional, capable, k...   \n",
       "\n",
       "  clean_aspect_term                                      weights_score  \\\n",
       "0           [staff]  {'But': 1.0, 'staff': 2, 'horrible': 1.0, 'u':...   \n",
       "1            [food]  {'To': 0.2, 'completely': 0.25, 'fair': 0.3333...   \n",
       "2            [food]  {'The': 1.0, 'food': 2, 'uniformly': 1.0, 'exc...   \n",
       "3         [kitchen]  {'The': 0.2, 'food': 0.25, 'uniformly': 0.3333...   \n",
       "4            [menu]  {'The': 0.07692307692307693, 'food': 0.0833333...   \n",
       "\n",
       "                                     element_weights  \n",
       "0  {'But': 1.0, 'staff': 2, 'horrible': 1.0, 'u':...  \n",
       "1  {'To': 0.2, 'completely': 0.25, 'fair': 0.3333...  \n",
       "2  {'The': 1.0, 'food': 2, 'uniformly': 1.0, 'exc...  \n",
       "3  {'The': 0.2, 'food': 0.25, 'uniformly': 0.3333...  \n",
       "4  {'The': 0.07692307692307693, 'food': 0.0833333...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#assign weights to the data\n",
    "df1['element_weights'] = df1[['clean_text','clean_aspect_term']].apply(assign_weights, axis = 1)\n",
    "\n",
    "#drop all nan values\n",
    "df1 = df1.dropna()\n",
    "\n",
    "#create an empty df with zeros\n",
    "df2 = pd.DataFrame(np.zeros((len(df1),len(vocab))),columns=vocab)\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the calculated weights to the corresponding text elements of df2\n",
    "for row in range(len(df1)):\n",
    "    for key,value in df1.iloc[row]['element_weights'].items():\n",
    "        df2.iloc[row][key] = value\n",
    "        \n",
    "#feature extraction - transform a count matrix to a normalized tf-idf representation\n",
    "tfidf= TfidfTransformer().fit_transform(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6613888888888889"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = LinearSVC(C=1.2)\n",
    "pred_SVM = cross_val_predict(svm,tfidf,df1['class'],cv = 10)\n",
    "\n",
    "np.mean(pred_SVM == df1['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.2, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(tfidf, df1['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.55610561, 0.42950108, 0.7287801 ]), array([0.41915423, 0.31279621, 0.85344429]), array([0.47801418, 0.36197441, 0.78620102]), array([ 804,  633, 2163], dtype=int64))\n",
      "\n",
      " Classification Report \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.42      0.56      0.48       606\n",
      "           0       0.31      0.43      0.36       461\n",
      "           1       0.85      0.73      0.79      2533\n",
      "\n",
      "   micro avg       0.66      0.66      0.66      3600\n",
      "   macro avg       0.53      0.57      0.54      3600\n",
      "weighted avg       0.71      0.66      0.68      3600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(precision_recall_fscore_support(df1['class'], pred_SVM, labels=[-1,0,1]))\n",
    "\n",
    "print(\"\\n Classification Report \\n \", classification_report(pred_SVM,df1['class']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(min_df = 0.00125, max_df = 0.7, sublinear_tf=True, use_idf=True, stop_words=u'english', analyzer= processData, ngram_range=(1,5),lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vec.fit_transform(df1['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df1['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier(max_depth=10).fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cross_val_predict(DT,X,Y,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(Y==pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(precision_recall_fscore_support(Y, pred, labels=[-1,0,1]))\n",
    "\n",
    "print(\"\\n Classification Report \\n \", classification_report(pred,Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_NB = MultinomialNB().fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_NB= cross_val_predict(clf_NB,X,Y,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(Y==pred_NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(precision_recall_fscore_support(Y, pred_NB, labels=[-1,0,1]))\n",
    "\n",
    "print(\"\\n Classification Report \\n \", classification_report(pred_NB,Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6566666666666666"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_RFC = RandomForestClassifier(n_estimators=100,max_depth=200)\n",
    "pred_RF = cross_val_predict(clf_RFC,df2,df1['class'],cv = 10)\n",
    "np.mean(pred_RF == df1['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.62678063, 0.44015444, 0.67892977]), array([0.27363184, 0.18009479, 0.93851133]), array([0.38095238, 0.25560538, 0.78789055]), array([ 804,  633, 2163], dtype=int64))\n",
      "\n",
      " Classification Report \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.27      0.63      0.38       351\n",
      "           0       0.18      0.44      0.26       259\n",
      "           1       0.94      0.68      0.79      2990\n",
      "\n",
      "   micro avg       0.66      0.66      0.66      3600\n",
      "   macro avg       0.46      0.58      0.47      3600\n",
      "weighted avg       0.82      0.66      0.71      3600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(precision_recall_fscore_support(df1['class'], pred_RF, labels=[-1,0,1]))\n",
    "\n",
    "print(\"\\n Classification Report \\n \", classification_report(pred_RF,df1['class']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the columns required\n",
    "testcols=['example_id','text','aspect_term','term_location']\n",
    "df_test = pd.read_csv('./Data-2_test.csv',skipinitialspace=True, usecols=testcols)\n",
    "\n",
    "df_test.columns = ['example_id','text','aspect_term','term_location']\n",
    "countVectorizer = CountVectorizer()\n",
    "count_matrix = countVectorizer.fit_transform(df_test['text'])\n",
    "df_test['text'] = df_test['text'].apply(processData)\n",
    "df_test['processed_AT'] = df_test['aspect_term'].apply(processData)\n",
    "df_test['element_weights'] = df_test[['text','processed_AT']].apply(assign_weights, axis = 1)\n",
    "df_test = df_test.dropna()\n",
    "df2_test = pd.DataFrame(np.zeros((len(df1),len(vocab))),columns=vocab)\n",
    "\n",
    "#assign weights and add it to the dict\n",
    "for row in range(len(df_test)):    \n",
    "    for key,value in df_test.iloc[row]['element_weights'].items():\n",
    "        df2_test.iloc[row][key] = value\n",
    "tfidf= TfidfTransformer().fit_transform(df2_test)\n",
    "\n",
    "#do a single pass over the test data using existing classifier \n",
    "pred_SVM = svm.predict(df2_test)\n",
    "res = list()\n",
    "file = open('KruneetKumar_Patel_Vishwas_SreevalliRamamohan_Data-2.txt','w')\n",
    "\n",
    "#zip example ids with their predictions and write it to a file\n",
    "for x,y in zip(list(df_test['example_id']),pred_SVM):\n",
    "    res.append(str(x) +\";;\"+str(y))\n",
    "for i in res:\n",
    "    file.write(\"%s\\n\"%i)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
   
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1120\n"
     ]
    }
   ],
   "source": [
    "i = 0 \n",
    "with open('Data-2.txt','r') as f:\n",
    "    x = f.readlines()\n",
    "    for y in x:\n",
    "        i += 1 \n",
    "print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1120"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(pred_SVM==[-1,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = df1.copy()\n",
    "df1['clean_text']= \" \".join(df1['clean_text'])\n",
    "vec = TfidfVectorizer(min_df = 0.00125, max_df = 0.7, sublinear_tf=True, use_idf=True, stop_words=u'english', analyzer= 'word', ngram_range=(1,5),lowercase=True)\n",
    "X = vec.fit_transform(data['text'])\n",
    "svm = LinearSVC(C=1.2)\n",
    "pred_weights = cross_val_predict(svm,X,data['class'],cv = 10)\n",
    "np.mean(pred_weights == data['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['sentText'] = [\" \".join(x) for x in df1['clean_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['sentAspect'] = [\" \".join(c) for c in df1['clean_aspect_term']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(min_df = 0.00125, max_df = 0.5, sublinear_tf=True, use_idf=True, stop_words=u'english', analyzer= 'word', ngram_range=(1,10),lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vec.fit_transform(df1['sentText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df1['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = LinearSVC(C=1.2)\n",
    "pred_weights = cross_val_predict(svm, X ,df1['class'],cv = 10)\n",
    "len(pred_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(pred_weights == df1['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
